---
layout: post
title: "Theano"
excerpt: "Test"
date: 2017-02-15
---

### 前言

下周又要开始实习了。想着在此之前再学一些实用的东西，临阵磨磨枪，于是便有了这个专题。[Theano](http://deeplearning.net/software/theano/) 是现在热门的几个深度学习工具库之一，基于python，简单易用。虽然现在有不少好用的基于 Theano 的库（如Keras, Lasagne等），但从基础学习一下 Theano 对更好的理解代码和开展实验都是有帮助的。这个专题是本人这几天学习的经验总结，目的是对现在网上流行的部分“热门教程”进行一番去伪存真，总结出一条短时间学习 Theano 的可行之路（本人花了远不止7个小时了...）。

本文适用的对象是：有足够的python和numpy编程基础、有足够的机器学习和深度学习算法基础。换句话说，什么都不缺，就是想多学个工具。哦，还要会英文。。。

读完本专题后你可以收获：1、对 Theano 的常用功能有足够的了解；2、了解 Theano 计算原理和流程；3、能够用 Theano 实现经典的深度学习算法（AlexNet、LSTM ...）。强烈建议将文中的代码全部手打实现一遍，你会发现比看要有用的多（看起来都很好理解）。

最后强调一下：本文不生产干货，只是干货的搬运工。本文大多数内容来自于网络的不同教程和资源，只是出于实用目的进行筛选和修改（文中的代码都经过本人验证及修改）。大部分参考资料来源于（其中介绍为网络评论）：
1. [theano_exercise](github.com/goodfeli/theano_exercises)：适合从零开始的学习，每个exercise带你认识theano的一个模块
2. [Theano-Tutorials](https://github.com/Newmu/Theano-Tutorials)：都说是见过的最好的theano tutorial
3. [官方tutorial](http://deeplearning.net/software/theano/tutorial/index.html#tutorial)
4. [官方deep learning tutorial](http://deeplearning.net/tutorial/)
5. [ipython](https://github.com/donnemartin/data-science-ipython-notebooks#deep-learning)：一系列数据科学的ipy notebook


第一天，我们会熟悉基本的 Theano 功能，并用其实现线性回归和Logistic回归模型，总共用时大概两个小时。其中选择的内容力求清楚、明确、好懂。

### 1、熟悉基本表达式
这一部分应该非常简单，但一些讲得不清楚的资料往往产生误导人的作用。Ian Goodfellow的这个[ppt](https://drive.google.com/file/d/0B64011x02sIkdDB5MmdnRnNTbWc/edit)讲的还算清楚，主要看看从scalar到tensor的定义。大概扫一眼就是了。

### 2、了解更多基本功能
接触了基本表达式后，我非常建议大家化30分钟左右时间浏览熟悉一下[这个页面](http://deeplearning.net/software/theano/library/tensor/basic.html#libdoc-basic-tensor)中的 Theano 基本功能。虽然这更像一个文档介绍，但是熟悉一下各种基本功能会对后面看代码有很大的帮助。当然，也是浏览一下就是了，主要可以熟悉以下一些点：

  - Converting from Python objects
  - TensorVariable
  - Shaping and Shuffling
  - Reduction
  - Indexing
  - Broadcasting in Theano vs. Numpy

### 3、了解 Theano Graph
尽早了解 Theano 的图结构，对理解 Theano 的计算原理和流程会有好处，也帮助理解之后的函数和梯度计算。推荐看官方教程的[这篇](http://deeplearning.net/software/theano/tutorial/symbolic_graphs.html)。弄清楚三个building blocks: Variable、Op 和 Apply。

### 4、学习 function
function是 Theano 最重要的函数之一了，也是至今为止比较复杂的一个功能。推荐看官方教程[这篇](http://deeplearning.net/software/theano/tutorial/examples.html#)里“Using Random Numbers”之前的部分。其中重点要理解的是 SharedVariable 和 updates 参数的用法。多读两遍吧 :)。

### 5、Check point：线性回归
好了，目前为止对 Theano 最基本的功能和用法有了一定的了解，我们用所学的知识实现一个线性回归模型吧！具体代码在：[这里](https://github.com/xyang35/learn_theano/blob/master/Day1/linear_regression.py)，来源于参考资料[2]，加了一些注释。注意理解function函数的使用方式。

在这个代码中，你会发现有一个你不熟悉的函数：grad()。没关系，我们下一步就来学习它。

### 6、学习梯度计算
Theano 一大利器是提供自动梯度计算功能，其实现原理其中在之前Kapathy课上讲解[Computational Graph]()的时候便有所介绍。其实很简单，推荐看看官方教程[这篇](http://deeplearning.net/software/theano/tutorial/gradients.html)的第一小节。后面的内容也可以稍微看看。

### 7、Check point: Logistic回归
学会怎么计算梯度之后，我们就可以使用梯度下降算法来训练一个Logistic回归模型了。具体代码在：[这里](https://github.com/xyang35/learn_theano/blob/master/Day1/logistic_regression.py)，修改于官方教程的例子。其中注意增加了损失函数的定义，以及对损失函数和变量进行的梯度计算，并把这些元素用function函数同一调用。

### 8、其他功能

  - 配置config：建议读官方教程的[这篇](http://deeplearning.net/software/theano/tutorial/modes.html)，以及第1步中[ppt](https://drive.google.com/file/d/0B64011x02sIkdDB5MmdnRnNTbWc/edit)讲config的部分。
  - Printing：建议看官方教程的[这篇](http://deeplearning.net/software/theano/tutorial/printing_drawing.html)，了解一下还是必要的。
  - 其他的，有空就再逛逛[官方教程](http://deeplearning.net/software/theano/tutorial/index.html#tutorial)吧。

### 小结
第一天的内容比较简单和基础，希望能够对 Theano 有初步的认识。能够实现一个Logistic回归还是挺不错的，在[Day 2]()里我们将开始实现神经网络了。回见！
